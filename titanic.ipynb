{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model that will be able to predict who could survive and who could die in the Titanic disaster, based on selected passenger information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display_html\n",
    "\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "from hyperopt import hp, STATUS_OK, Trials, fmin, tpe, partial\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/titanic_train.csv')\n",
    "test_data = pd.read_csv('data/titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['IsCabin'] = train_data.Cabin.fillna(0)\n",
    "train_data.loc[train_data.IsCabin != 0, 'IsCabin'] = 1\n",
    "train_data.IsCabin = train_data.IsCabin.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['IsCabin'] = test_data.Cabin.fillna(0)\n",
    "test_data.loc[test_data.IsCabin != 0, 'IsCabin'] = 1\n",
    "test_data.IsCabin = test_data.IsCabin.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.drop(columns='Survived', axis=1).append(test_data).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic visualization of existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 15))\n",
    "fig.suptitle(\"0 - No, 1 - Yes\", fontsize=25, y=1.05)\n",
    "plt.subplot2grid((4, 3), (0, 0))\n",
    "sns.boxplot(x='Survived', y='Age', data=train_data, orient='v')\n",
    "plt.title('Age')\n",
    "plt.subplot2grid((4, 3), (0, 1))\n",
    "sns.boxplot(x='Survived', y='Fare', data=train_data, orient='v')\n",
    "plt.title('Fare')\n",
    "plt.subplot2grid((4, 3), (0, 2))\n",
    "sns.countplot(x='Sex', hue='Survived', data=train_data)\n",
    "plt.subplot2grid((4, 3), (1, 0))\n",
    "sns.countplot(x='Survived', data=train_data)\n",
    "plt.title('Survived')\n",
    "plt.subplot2grid((4, 3), (1, 1))\n",
    "sns.countplot(x='Pclass', data=train_data)\n",
    "plt.title('Pclass')\n",
    "plt.subplot2grid((4, 3), (1, 2))\n",
    "sns.countplot(x='Embarked', data=train_data)\n",
    "plt.title('Embarked')\n",
    "plt.subplot2grid((4, 3), (2, 0))\n",
    "sns.countplot(x='Pclass', hue='Survived', data=train_data)\n",
    "plt.title('Pclass by Survived/Died')\n",
    "plt.subplot2grid((4, 3), (2, 1))\n",
    "sns.countplot(x='SibSp', hue='Survived', data=train_data)\n",
    "plt.title('SibSP by Survived/Died')\n",
    "plt.subplot2grid((4, 3), (2, 2))\n",
    "sns.countplot(x='Parch', hue='Survived', data=train_data)\n",
    "plt.title('Parch by Survived/Died')\n",
    "plt.subplot2grid((4, 3), (3, 0))\n",
    "sns.countplot(x='IsCabin', hue='Survived', data=train_data)\n",
    "plt.title('Cabin or not by Survived')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data - version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Fare by Embarked for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_v2.loc[:][data_v2.Fare.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Fare = data_v2.Fare.fillna(data_v2.Fare[(data_v2.Embarked == 'S') & (data_v2.Pclass == 3)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Age = data_v2.Age.fillna(data_v2.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data_v2.Age, kde=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common Embarked value for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Embarked.value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Embarked = data_v2.Embarked.fillna(data_v2.Embarked.value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping values for Embarked:\n",
    "S -> 1  \n",
    "C -> 2  \n",
    "Q -> 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Embarked = data_v2.Embarked.map({'S': 1, 'C': 2, 'Q': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.Sex = data_v2.Sex.replace('female', 0)\n",
    "data_v2.Sex = data_v2.Sex.replace('male', 1)\n",
    "data_v2.Sex.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Fare Per Passenger Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data_v2.Fare, kde=False, norm_hist=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_counts = data_v2.Ticket.value_counts()\n",
    "tickets_index = ticket_counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempor_tickets = pd.Series(ticket_counts, index=tickets_index)\n",
    "tempor_fares = pd.Series(data_v2.groupby('Ticket')['Fare'].mean(), index=tickets_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_pp = pd.DataFrame({'Count': ticket_counts,\n",
    "                           'Fare': tempor_fares}, index=tickets_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_pp['FarePerPassenger'] = fare_pp.apply(lambda x: x.Fare/x.Count, axis=1)\n",
    "fare_pp.index = fare_pp.index.rename('Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2 = data_v2.join(fare_pp.loc[:,['FarePerPassenger']], on='Ticket')\n",
    "data_v2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data - version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing datasets to making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_train = train_data.Survived\n",
    "data_v1 = train_data.drop('Survived', axis=1).append(test_data, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mark cabins by its type and missing values by \"noCabin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.Cabin = data.Cabin.str[0]\n",
    "data_v1.Cabin = data.Cabin.fillna('noCabin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing values of sex variable to 0 (female) and 1 (male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.Sex = data_v1.Sex.replace('female', 0)\n",
    "data_v1.Sex = data_v1.Sex.replace('male', 1)\n",
    "data_v1.Sex= data_v1.Sex.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How big a family a passenger has and what is the distribution of this variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1['FamilySize'] = data_v1.SibSp + data_v1.Parch + 1\n",
    "data_v1['IsSolo'] = 0\n",
    "data_v1.loc[data_v1.FamilySize == 1, 'IsSolo'] = 1\n",
    "data_v1['SmallGroup'] = 0\n",
    "data_v1.loc[data_v1.FamilySize.isin([2, 3, 4]), 'SmallGroup'] = 1\n",
    "sns.countplot(data_v1['FamilySize']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting titles of passengers and presenting distribution of age by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1['Title'] = data_v1['Name'].str.replace('(.*, )|(\\. .*)', '')\n",
    "data_v1.Title = data_v1.Title.replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'lady')\n",
    "data_v1.Title = data_v1.Title.replace(['Don', 'Major', 'Sir', 'Col', 'Capt', 'Jonkheer'], 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot2grid((1, 3), (0, 0))\n",
    "sns.boxplot(x='Title', y='Age', data=data_v1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the age is unknown, the passenger receives the average age from the title category to which he belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in data_v1.Title.unique().tolist():\n",
    "    data_v1.loc[data_v1.Title == title, ['Age']] = data_v1.loc[data_v1.Title == title, ['Age']].fillna(data_v1.loc[data_v1.Title == title, ['Age']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating fare per passenger and presenting its distribution in the dataset (median for missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = set(data_v1.Ticket)\n",
    "ticket_numbers = []\n",
    "fares = []\n",
    "\n",
    "for ticket in tickets:\n",
    "    ticket_numbers.append(len(data_v1[data_v1.Ticket == ticket]))\n",
    "    fares.append(data_v1['Fare'][data_v1.Ticket == ticket].mean())\n",
    "\n",
    "tickets_sum = pd.DataFrame()\n",
    "tickets_sum['Ticket'] = list(tickets)\n",
    "tickets_sum['Count'] = ticket_numbers\n",
    "tickets_sum['Fare'] = fares\n",
    "tickets_sum['FarePP'] = tickets_sum['Fare']/tickets_sum['Count']\n",
    "tickets_sum = tickets_sum.drop(['Count', 'Fare'], axis=1)\n",
    "\n",
    "data_v1 = pd.merge(data_v1, tickets_sum, 'left', 'Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.FarePP = data_v1.FarePP.fillna(data_v1.FarePP.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.distplot(a=data_v1.FarePP, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_feats = ['PassengerId', 'SibSp', 'Parch', 'FarePP', 'FamilySize']\n",
    "dummy_feats = ['Sex', 'Pclass', 'IsSolo', 'SmallGroup', 'Title']\n",
    "\n",
    "data_v2_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'IsCabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = data_v1.loc[:, orig_feats]\n",
    "dummy_df = pd.get_dummies(data_v1.loc[:, dummy_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting features and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_v2.loc[:, data_v2_features]\n",
    "df = pd.concat([orig_df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[890:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset to train, validation and submission subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:890,]\n",
    "y = survived_train\n",
    "test_x = df.loc[891:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures(y, pred_y):\n",
    "    score_test = roc_auc_score(y, pred_y)\n",
    "    gini_index = 2*score_test-1\n",
    "    \n",
    "    df = pd.DataFrame({'AUC': [round(score_test, 4)], 'Gini': [round(gini_index, 4)]})\n",
    "    return df\n",
    "\n",
    "def calculating_metrics(model, test_x, val_x, test_y, val_y):\n",
    "    test = get_measures(test_y, model.predict_proba(test_x)[:, 1])\n",
    "    val = get_measures(val_y, model.predict_proba(val_x)[:, 1])\n",
    "    \n",
    "    return pd.concat([test, val]).set_index([pd.Index(['TRAIN', 'VAL'])])\n",
    "\n",
    "def get_performance_measure(y, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y[i]==y_pred[i] and y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y[i]==y_pred[i] and y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "def print_indicators(real_y, predict_y):\n",
    "    TP, FP, TN, FN = get_performance_measure(real_y, predict_y)\n",
    "    \n",
    "\n",
    "    pos = TP + FN\n",
    "    neg = TN + FP\n",
    "\n",
    "    tpr = TP / (TP + FN)\n",
    "    tnr = TN / (TN + FP)\n",
    "    fpr = FP / (FP + TN)\n",
    "    fnr = FN / (FN + TP)\n",
    "\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    msg = (f'Number of positive observations:\\t\\t{pos}\\n'\n",
    "           f'Number of negative observations:\\t\\t{neg}\\n'\n",
    "           f'Total number of observations:\\t\\t\\t{pos+neg}\\n\\n'\n",
    "           f'TPR (True Positive Rate), SE (sensitivity):\\t{tpr:.4f}\\n'\n",
    "           f'TNR (True Negative Rate), SPC (specificity):\\t{tnr:.4f}\\n'\n",
    "           f'FPR (False Positive Rate):\\t\\t\\t{fpr:.4f}\\n'\n",
    "           f'FNR (False Negative Rate):\\t\\t\\t{fnr:.4f}\\n'\n",
    "           f'ACC (Total Accuracy):\\t\\t\\t\\t{acc:.4f}'\n",
    "          )\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DTC = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for Decision Tree model using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_random_param = {\n",
    "    'max_depth': np.linspace(1, 15, 15),\n",
    "    'min_samples_split': np.linspace(0.01, 1, 10),\n",
    "    'min_samples_leaf': np.linspace(0.01, 0.5, 5),\n",
    "    'max_features': list(range(1, train_x.shape[1])),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model_DTC, grid_random_param, scoring='roc_auc')\n",
    "grid.fit(train_x, train_y)\n",
    "best_parameters_DTC_grid = grid.best_params_\n",
    "print(best_parameters_DTC_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with the best-chosen parameters, predict values and get basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_GS = DecisionTreeClassifier(**best_parameters_DTC_grid, random_state=1)\n",
    "model_GS.fit(train_x, train_y)\n",
    "cm_DTC_GS = calculating_metrics(model_GS, train_x, val_x, train_y, val_y)\n",
    "cm_DTC_GS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix_dtc_gs = confusion_matrix(val_y, model_GS.predict(val_x))\n",
    "print(c_matrix_dtc_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measures based on a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y = val_y.to_numpy(dtype=int)\n",
    "predict_y = model_GS.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nTN:\\t{c_matrix_dtc_gs[0][0]}\\nFN:\\t{c_matrix_dtc_gs[1][0]}\\nTP:\\t{c_matrix_dtc_gs[1][1]}\\nFP:\\t{c_matrix_dtc_gs[0][1]}\\n')\n",
    "print(print_indicators(real_y, predict_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model_GS.predict_proba(val_x)\n",
    "fpr_dtc_gs, tpr_dtc_gs, th = roc_curve(val_y, pred_prob[:, 1])\n",
    "auc_dts_gs = roc_auc_score(val_y, pred_prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr_dtc_gs, tpr_dtc_gs, 'o-')\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "print(f'AUC: {auc_dts_gs:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIFT chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(val_y, pred_prob);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for Decision Tree model using Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(model_DTC, grid_random_param, n_iter=200, scoring='roc_auc')\n",
    "random_search.fit(train_x, train_y)\n",
    "best_parameters_DTC_random = random_search.best_params_\n",
    "print(best_parameters_DTC_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with the best-chosen parameters, predict values and get basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RS = DecisionTreeClassifier(**best_parameters_DTC_random, random_state=1)\n",
    "model_RS.fit(train_x, train_y)\n",
    "cm_DTC_RS = calculating_metrics(model_RS, train_x, val_x, train_y, val_y)\n",
    "cm_DTC_RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for Decision Tree model using Baysian optimalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_startup_jobs = 80\n",
    "max_evals = 500\n",
    "BS_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_opt_space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 15, 1),\n",
    "    'min_samples_split': hp.uniform('min_samples_split', 0.01, 1),\n",
    "    'min_samples_leaf': hp.uniform('min_samples_leaf', 0.01, 0.5),\n",
    "    'max_features': hp.quniform('max_features', 1, train_x.shape[1], 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    b_params = {\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'min_samples_split': space['min_samples_split'],\n",
    "        'min_samples_leaf': space['min_samples_leaf'],\n",
    "        'max_features': int(space['max_features'])\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**b_params, random_state=0)\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(val_x)\n",
    "    \n",
    "    score = -roc_auc_score(val_y, pred_y)\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_parameters_DTC_bayesian = fmin(fn=objective,\n",
    "                   space=b_opt_space, \n",
    "                   algo=partial(tpe.suggest, n_startup_jobs=n_startup_jobs),\n",
    "                   max_evals=max_evals,\n",
    "                   trials=trials\n",
    "                  )\n",
    "print(f'best params: {best_parameters_DTC_bayesian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters_DTC_bayesian['max_features'] = int(best_parameters_DTC_bayesian['max_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with the best-chosen parameters, predict values and get basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_BO = DecisionTreeClassifier(**best_parameters_DTC_bayesian, random_state=1)\n",
    "model_BO.fit(train_x, train_y)\n",
    "cm_DTC_BO = calculating_metrics(model_BO, train_x, val_x, train_y, val_y)\n",
    "cm_DTC_BO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of prediction results with using Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DTC = pd.concat([cm_DTC_GS, cm_DTC_RS, cm_DTC_BO],\n",
    "                        axis=1,\n",
    "                        keys={'GidSearchCV': cm_DTC_GS,\n",
    "                              'RandomSearchCV': cm_DTC_RS,\n",
    "                              'Bayesian Optimization': cm_DTC_BO}\n",
    "                       )\n",
    "results_DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RFC = RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for Random Forest model using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_random_param_RFC = {\n",
    "    'n_estimators': [200, 250, 300],\n",
    "    'max_depth': [20, None],\n",
    "    'min_samples_split': [5, 10, 12],\n",
    "    'min_samples_leaf': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RFC_GS = GridSearchCV(model_RFC, grid_random_param_RFC, scoring='roc_auc')\n",
    "grid_RFC_GS.fit(train_x, train_y)\n",
    "best_parameters_RFC_grid = grid_RFC_GS.best_params_\n",
    "print(best_parameters_RFC_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with the best-chosen parameters, predict values and get basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RFC_GS = RandomForestClassifier(**best_parameters_RFC_grid, random_state=1)\n",
    "model_RFC_GS.fit(train_x, train_y)\n",
    "cm_RFC_GS = calculating_metrics(model_RFC_GS, train_x, val_x, train_y, val_y)\n",
    "cm_RFC_GS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for Random Forest model using Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_RFC_RS = RandomizedSearchCV(model_RFC, grid_random_param_RFC, scoring='roc_auc')\n",
    "random_RFC_RS.fit(train_x, train_y)\n",
    "best_parameters_RFC_random = random_RFC_RS.best_params_\n",
    "print(best_parameters_RFC_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with the best-chosen parameters, predict values and get basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RFC_RS = RandomForestClassifier(**best_parameters_RFC_random, random_state=1)\n",
    "model_RFC_RS.fit(train_x, train_y)\n",
    "cm_RFC_RS = calculating_metrics(model_RFC_RS, train_x, val_x, train_y, val_y)\n",
    "cm_RFC_RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for Random Forest model using Baysian optimalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_opt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 200, 300, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 10, 30, 2),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 4, 116, 2),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 8, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    b_opt_space = {\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'min_samples_split': int(space['min_samples_split']),\n",
    "        'min_samples_leaf': int(space['min_samples_leaf']),\n",
    "    }\n",
    "    model = RandomForestClassifier(**b_opt_space, random_state=0)\n",
    "    model.fit(train_x, train_y)\n",
    "    pred_y = model.predict(val_x)\n",
    "    score = -roc_auc_score(val_y, pred_y)\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_parameters_RFC_bayesian = fmin(fn=objective,\n",
    "                                    space=b_opt_space,\n",
    "                                    algo=partial(tpe.suggest, n_startup_jobs=n_startup_jobs),\n",
    "                                    max_evals=max_evals,\n",
    "                                    trials=trials\n",
    "                                   )\n",
    "print(f'best params: {best_parameters_RFC_bayesian}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters_RFC_bayesian['n_estimators'] = int(best_parameters_RFC_bayesian['n_estimators'])\n",
    "best_parameters_RFC_bayesian['max_depth'] = int(best_parameters_RFC_bayesian['max_depth'])\n",
    "best_parameters_RFC_bayesian['min_samples_split'] = int(best_parameters_RFC_bayesian['min_samples_split'])\n",
    "best_parameters_RFC_bayesian['min_samples_leaf'] = int(best_parameters_RFC_bayesian['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with the best-chosen parameters, predict values and get basic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RFC_BO = RandomForestClassifier(**best_parameters_RFC_bayesian, random_state=0)\n",
    "model_RFC_BO.fit(train_x, train_y)\n",
    "cm_RFC_BO = calculating_metrics(model_RFC_BO, train_x, val_x, train_y, val_y)\n",
    "cm_RFC_BO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of prediction results with using Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RFC = pd.concat([cm_RFC_GS, cm_RFC_RS, cm_RFC_BO],\n",
    "                        axis=1,\n",
    "                        keys={'GidSearchCV': cm_RFC_GS,\n",
    "                              'RandomSearchCV': cm_RFC_RS,\n",
    "                              'Bayesian Optimization': cm_RFC_BO}\n",
    "                       )\n",
    "results_RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DTC.index = pd.MultiIndex.from_product([['Decision Tree'], ['Train', 'Val']])\n",
    "results_RFC.index = pd.MultiIndex.from_product([['Random Forest'], ['Train', 'Val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summ = results_DTC.append(results_RFC)\n",
    "results_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K nearest neighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(scale.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_scaled = pd.DataFrame(scale.fit_transform(test_x), columns=test_x.columns)\n",
    "train_x_s, val_x_s, train_y_s, val_y_s = train_test_split(X_scaled, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 20):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i).fit(train_x_s, train_y_s)\n",
    "    print(knn_model.score(val_x_s, val_y_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculating_metrics(KNeighborsClassifier(n_neighbors=11).fit(val_x_s, val_y_s), train_x_s, val_x_s, train_y_s, val_y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score = validation_curve(KNeighborsClassifier(),\n",
    "                                           X,\n",
    "                                           y,\n",
    "                                           param_name='n_neighbors',\n",
    "                                           param_range=range(1, 21),\n",
    "                                           cv=5\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_mean = np.mean(train_score, axis=1)\n",
    "test_score_mean = np.mean(test_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.set_style('ticks')\n",
    "sns.lineplot(x=range(1,21), y=train_score_mean, markers=True, marker='o', )\n",
    "sns.lineplot(x=range(1,21), y=test_score_mean, markers=True, marker='o')\n",
    "plt.legend(['train score', 'test score'])\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = model_RFC_BO.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_values = pd.Series(pred_values, name='Survived', index=range(len(pred_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.Survived = subm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('data/gender_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
